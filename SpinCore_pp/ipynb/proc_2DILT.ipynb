{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used in the modified BRD 2D-ILT procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#References\n",
    "#Venkataramanan et al. - 2002 (DOI : 10.1109/78.995059)\n",
    "#Mitchell et al. - 2012 (DOI : 10.1016/j.pnmrs.2011.07.002)\n",
    "def nnls_reg(val):\n",
    "    r'''A function that initializes the storage arrays and performs nnls using smoothing parameter :val:\n",
    "        Calls function :A_prime: which generates the smoothing matrix for the fit and :b_prime: which is\n",
    "        the lexicographically ordered data, extended by zeros to match the dimensions of the fit matrix.\n",
    "    Parameters\n",
    "    ----------\n",
    "    val : float\n",
    "        The smoothing parameter lambda (= sqrt(alpha))\n",
    "    '''\n",
    "    r_norm = empty([1])\n",
    "    x,r_norm[0] = nnls(A_prime(val,dimension),b_prime)\n",
    "    return x\n",
    "\n",
    "def chi(x_vec,val):\n",
    "    r'''The function that minimizes the c_r vector derived from Kuhn-Tucker conditions.\n",
    "        Eq[31] in Venkataramanan et al. - 2002.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_vec : array\n",
    "        The c_r vector\n",
    "    val : float\n",
    "        The smoothing parameter lambda, which is converted to alpha (i.e., lambda**2)\n",
    "        in the function.\n",
    "    '''\n",
    "    return 0.5*dot(x_vec.T,dot(dd_chi(G(x_vec),val**2),x_vec)) - dot(x_vec.T,m_vec)\n",
    "\n",
    "def d_chi(x_vec,val):\n",
    "    r'''The derivative of :chi:, which serves as the input function to the Newton Minimization\n",
    "        procedure -- i.e., we find the zeros of this function which correspond to maxima or minima\n",
    "        of :chi:\n",
    "        Eq[32] in Venkataramanan et al. - 2002.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_vec : array\n",
    "        The c_r vector\n",
    "    val : float\n",
    "        The smoothing parameter lambda, which is converted to alpha (i.e., lambda**2)\n",
    "        in the function.\n",
    "    '''\n",
    "    return dot(dd_chi(G(x_vec),val**2),x_vec) - m_vec\n",
    "\n",
    "def dd_chi(G,val):\n",
    "    r'''The second derivative of :chi:, which serves as the derivative of the input function to the\n",
    "        Newton Minimization procedure -- i.e., we find the zeros of this function which correspond to\n",
    "        maxima or minima of :chi:\n",
    "        Eq[33] in Venkataramanan et al. - 2002.\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : matrix\n",
    "        The diagonal matrix, see :G: \n",
    "    val : float\n",
    "        The smoothing parameter lambda, which is converted to alpha (i.e., lambda**2)\n",
    "        in the function.\n",
    "    '''\n",
    "    return G + (val**2)*eye(shape(G)[0])\n",
    "\n",
    "def G(x_vec):\n",
    "    r'''The symmetric matrix used in the BRD algorithm.   \n",
    "        Eq[30] in Venkataramanan et al. - 2002.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_vec : array\n",
    "        The c_r vector\n",
    "    '''\n",
    "    return dot(K0,dot(square_heaviside(x_vec),K0.T))\n",
    "\n",
    "def H(product):\n",
    "    r'''A simple heaviside function, used in :G:\n",
    "        See eq[30] in Venkataramanan et al. - 2002.\n",
    "    Parameters\n",
    "    ----------\n",
    "    product : float\n",
    "        The product of dotting a row element of the tensor product kernel with the\n",
    "        c_r vector, used in :G:.\n",
    "        See eq[30] in Venkataramanan et al. - 2002.\n",
    "    '''\n",
    "    if product <= 0:\n",
    "        return 0\n",
    "    if product > 0:\n",
    "        return 1\n",
    "\n",
    "def square_heaviside(x_vec):\n",
    "    r'''The diagonal matrix used in :G:\n",
    "        See eq[30] in Venkataramanan et al. - 2002.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_vec : array\n",
    "        The c_r vector\n",
    "    '''\n",
    "    diag_heavi = []\n",
    "    for q in xrange(shape(K0.T)[0]):\n",
    "        pull_val = dot(K0.T[q,:],x_vec)\n",
    "        temp = pull_val[0]\n",
    "        temp = H(temp)\n",
    "        diag_heavi.append(temp)\n",
    "    diag_heavi = array(diag_heavi)\n",
    "    square_heavi = diag_heavi*eye(shape(diag_heavi)[0])\n",
    "    return square_heavi\n",
    "\n",
    "def newton_min(input_vec,val):\n",
    "    r'''The Newton-Raphson minimization algorithm, provided by scipy.optimize.newton,\n",
    "        which needs to be redefined to enable the use of vectors and matrices in the\n",
    "        minimization procedure. Performs a single minimization to optimize the c_r\n",
    "        vector.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_vec : array\n",
    "        The c_r vector generated from the NNLS output.\n",
    "        Eq[26] in Venkataramanan et al. - 2002.\n",
    "    val : float\n",
    "        The smoothing parameter lambda, which is converted to alpha (i.e., lambda**2)\n",
    "        in the function.\n",
    "    '''\n",
    "    fder = dd_chi(G(input_vec),val)\n",
    "    fval = d_chi(input_vec,val)\n",
    "    newton_step = dot(linalg.inv(fder),fval)\n",
    "    update_vec = input_vec + newton_step\n",
    "    return update_vec\n",
    "\n",
    "def optimize_alpha(input_vec,val):\n",
    "    r'''Optimizes the smoothing parameter using eq[48] in Venkataramanan et al. - 2002.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_vec : array\n",
    "        The optimized c_r vector generated from Newton Minimization procedure.\n",
    "        Eq[26] in Venkataramanan et al. - 2002.\n",
    "    val : float\n",
    "        The smoothing parameter lambda, which is converted to alpha (i.e., lambda**2)\n",
    "        in the function.\n",
    "    '''\n",
    "    alpha_converged = False\n",
    "    fac = sqrt(choose_s1*choose_s2)\n",
    "    T = linalg.inv(dd_chi(G(input_vec),val**2))\n",
    "    dot_prod = dot(input_vec.T,dot(T,input_vec))\n",
    "    ans = dot_prod*fac\n",
    "    ans = ans/linalg.norm(input_vec)\n",
    "    ans = ans/(dot_prod)\n",
    "    tol = 1e-3\n",
    "    if abs(ans-val**2) <= tol:\n",
    "        print \"ALPHA HAS CONVERGED\"\n",
    "        alpha_converged = True\n",
    "        return ans,alpha_converged\n",
    "    return ans,alpha_converged\n",
    "\n",
    "def mod_BRD(guess,maxiter=20):\n",
    "    r'''The modified BRD method presented in Venkataramanan et al. - 2002\n",
    "        for optimizing the smoothing parameter using to regualrize the NNLS fit.\n",
    "    Parameters\n",
    "    ----------\n",
    "    guess : float\n",
    "        The initial smoothing parameter as lambda - i.e., sqrt(alpha). Algorithm\n",
    "        should converge within a few steps irrespective of this guess.\n",
    "    maxiter : int\n",
    "        The maximum number of iterations for the algorithm, set to 20 by default.\n",
    "        Should not need to be more than this.\n",
    "     '''\n",
    "    smoothing_param = guess\n",
    "    alpha_converged = False\n",
    "    for iter in xrange(maxiter):\n",
    "        print \"*** *** ITERATION NO.\",iter,\"*** ***\"\n",
    "        print \"*** CURRENT LAMBDA\",smoothing_param,\" *** \"\n",
    "        x_norm = empty([1])\n",
    "        r_norm = empty([1])\n",
    "        soln,r_norm = nnls(A_prime(smoothing_param,dimension),b_prime)\n",
    "        f_vec = soln[:,newaxis]\n",
    "        alpha = smoothing_param**2\n",
    "        c_vec = dot(K0,f_vec) - m_vec\n",
    "        c_vec /= -alpha\n",
    "        new_c = newton_min(c_vec,smoothing_param)\n",
    "        new_alpha,alpha_converged = optimize_alpha(new_c,smoothing_param)\n",
    "        new_lambda = sqrt(new_alpha[0,0])\n",
    "        if alpha_converged:\n",
    "            print \"*** OPTIMIZED LAMBDA\",new_lambda,\" *** \"\n",
    "            break  \n",
    "        if not alpha_converged:\n",
    "            print \"*** UPDATED LAMBDA\",new_lambda,\" *** \"\n",
    "            smoothing_param = new_lambda\n",
    "        if iter == maxiter-1:\n",
    "            print \"DID NOT CONVERGE.\"\n",
    "    return new_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspecdata import *\n",
    "from pyspecdata.load_files.bruker_nmr import bruker_data\n",
    "from scipy.optimize import nnls\n",
    "def fancy_legend():\n",
    "    legend(**dict(bbox_to_anchor=(1.05,1), loc=2, borderaxespad=0.))\n",
    "\n",
    "exp_name = 'test_CPMG_180808_CdSeS_663'\n",
    "expno = 4\n",
    "absvis = lambda x: abs(x).convolve('t2',10).real\n",
    "phvis = lambda x: x.C.convolve('t2',10)\n",
    "def cropvis(d, at=1e-3):\n",
    "    retval = phvis(d)\n",
    "    newabs = abs(retval)\n",
    "    level = newabs.data.max()*at\n",
    "    newabs[lambda x: x>level] = level\n",
    "    retval *= newabs/abs(retval)\n",
    "    return retval\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d = find_file(exp_name, exp_type='NMR_Data_EGR', dimname='indirect', expno=expno)\n",
    "n_indirect = d.get_prop('acq')['L'][23] # changed to l23 from pp\n",
    "print \"number of delays (tau 1):\",n_indirect\n",
    "with figlist_var() as fl:\n",
    "    # convolving to visualize better\n",
    "    plot_raw = True\n",
    "    absvis = lambda x: abs(x).convolve('t2',0.1).real\n",
    "    use_bad_hack = True\n",
    "    if use_bad_hack:\n",
    "        # this is a hack to at least get rid of the large data in Emily's bad dataset\n",
    "        for j in r_[65,131,197]:\n",
    "            d['t2':(6,None)]['indirect',j] = 0\n",
    "            d['t2',0]['indirect',j] = 0\n",
    "            d['t2',-1]['indirect',j] = 0\n",
    "    if plot_raw:\n",
    "        fl.next('raw data', figsize=(4,14))\n",
    "        fl.image(absvis(d))\n",
    "        fl.show()\n",
    "    d.setaxis('indirect',None)\n",
    "    print \"shape before chunking along indirect\",ndshape(d)\n",
    "    d.chunk('indirect',['indirect','phcyc'],[n_indirect,-1])\n",
    "    print \"shape after chunking along indirect\",ndshape(d)\n",
    "    fl.next('after chunk',figsize=(8,30))\n",
    "    fl.image(abs(d))\n",
    "    d.chunk('phcyc',['ph3','ph2','ph1'],[2,4,2])\n",
    "chunk_checkpoint = d.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = chunk_checkpoint.C\n",
    "orig_t = d.getaxis('t2').copy()\n",
    "d.setaxis('ph1',r_[0,2.]/4)\n",
    "d.setaxis('ph2',r_[0,1,2,3.]/4)\n",
    "d.setaxis('ph3',r_[0,2.]/4)\n",
    "print \"vdlist is:\",d.get_prop('vd')\n",
    "d.setaxis('indirect',d.get_prop('vd'))\n",
    "d.ft(['ph3','ph2','ph1'])\n",
    "d.reorder(['indirect','t2'],first=False)\n",
    "visualize_ph_cycling = False\n",
    "if visualize_ph_cycling:\n",
    "    with figlist_var() as fl:\n",
    "        fl.next('after phase cycle',figsize=(8,14))\n",
    "        fl.image(absvis(d))\n",
    "        fl.next('after phase cycle, ph',figsize=(8,14))\n",
    "        fl.image(d)\n",
    "phcyc_checkpoint = d.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = phcyc_checkpoint.C\n",
    "d = d['ph3',0]['ph1',0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_echoes = d.get_prop('acq')['L'][12]\n",
    "n_delays = len(d.getaxis('indirect'))\n",
    "SW = d.get_prop('acq')['SW']\n",
    "SFO1 = d.get_prop('acq')['SFO1']\n",
    "SWH = SW*SFO1\n",
    "DW = 1.0/SWH\n",
    "t2 = len(d.getaxis('t2'))\n",
    "tau2 = t2/n_delays\n",
    "print \"Number of echoes:\",n_echoes\n",
    "d.setaxis('t2',None)\n",
    "ndshape(d.chunk('t2',['echo','t2'],[n_echoes,-1]))\n",
    "d.setaxis('t2',orig_t[:ndshape(d)['t2']])\n",
    "t2_len = d.getaxis('t2')[-1]\n",
    "d.setaxis('t2', lambda x: x-t2_len/2)\n",
    "d.setaxis('echo',r_[:n_echoes])\n",
    "echochunk_checkpoint = d.C\n",
    "figure(figsize=(8,18))\n",
    "image(abs(d)['ph2',1]);show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = echochunk_checkpoint.C\n",
    "d.ft('t2',shift=True)\n",
    "d *= exp(1j*(140.*pi/180)/2.1e3*d.fromaxis('t2'))\n",
    "d_forplot = d.C.convolve('t2',10)\n",
    "d_ph = d_forplot['indirect',-1].C.run(sum,'t2')\n",
    "d_ph /= abs(d_ph)\n",
    "d_forplot /= d_ph\n",
    "#NOTE: ['ph2',1] are odd echoes and ['ph2',-1] are even echoes\n",
    "#Thus here we only image the odd echoes\n",
    "figure(figsize=(20,18))\n",
    "image(cropvis(d_forplot['ph2',1],at=0.1), black=True);show()\n",
    "figure(figsize=(20,18))\n",
    "image(d_forplot['ph2',1].real);show()\n",
    "figure(figsize=(20,18))\n",
    "image(d_forplot['ph2',1].imag);show()\n",
    "#image(d_forplot['ph2',1], black=True);show()\n",
    "ph_checkpoint = d_forplot.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interleaving echoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = ph_checkpoint.C\n",
    "\n",
    "#figure(figsize=(10,10));image(d['ph2',1]['echo',1::2],black=True);show()\n",
    "#figure();image(d['ph2',-1]['echo',0::2],black=True);show()\n",
    "\n",
    "with figlist_var() as fl:\n",
    "    for indirect_idx,indirect_val in enumerate(d.getaxis('indirect')):\n",
    "        even = d['ph2',-1]['echo',1::2]\n",
    "        odd = d['ph2',1]['echo',0::2]\n",
    "        fl.next('image even')\n",
    "        fl.image(cropvis(even))\n",
    "        fl.next('image odd')\n",
    "        fl.image(cropvis(odd))\n",
    "        #}}}\n",
    "        phdiff = even/odd*abs(odd)\n",
    "        fl.next('phase diff')\n",
    "        fl.image(cropvis(phdiff))\n",
    "        even_minus_odd_ph = phdiff.data.mean()\n",
    "        even_minus_odd_ph /= abs(even_minus_odd_ph)\n",
    "        print \"FOR DELAY\",indirect_idx,\"=\",indirect_val,\"s PHASE DIFF IS\",format(angle(even_minus_odd_ph)*180/pi)\n",
    "        fl.next('Interleaving echoes')\n",
    "        d_interleaved = d['ph2',1]\n",
    "        d_interleaved['echo',1::2] = d['ph2',-1]['echo',1::2].run(conj)\n",
    "        fl.image(cropvis(d_interleaved))\n",
    "print ndshape(d_interleaved) \n",
    "fl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = d_interleaved.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For determining 'NOISE FLOOR' as described in Mitchell et al. - 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.sum('t2')\n",
    "floor = d.imag['echo':(d.getaxis('echo')[5],d.getaxis('echo')[-1])]\n",
    "devi_list = []\n",
    "for x in xrange(len(floor.getaxis('indirect'))):\n",
    "    devi_list.append(std(floor['indirect',x].data))\n",
    "noise_floor = sum(devi_list)/len(devi_list)\n",
    "print \"Noise floor (standard deviation of imaginary channel) is \",noise_floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum along T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = d_interleaved\n",
    "t2 = len(d.getaxis('t2'))\n",
    "n_tau2 = len(d.getaxis('echo'))\n",
    "d_sum = d.C.sum('t2')\n",
    "d_sum = d_sum.real\n",
    "data = d_sum.C\n",
    "data.rename('indirect','tau1')\n",
    "data.rename('echo','tau2')\n",
    "print ndshape(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load interactive plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_nd = data.C\n",
    "data_nd.meshplot(cmap=cm.viridis)\n",
    "show()\n",
    "print ndshape(data_nd)\n",
    "data = data_nd.data\n",
    "print shape(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn off interactive plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire 2D ILT procedure (as described in Venkataramanan et al. 2002) below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Note notation is consistent with that used in Venkataramanan et al. 2002, but varies from ref to ref\n",
    "#Note importance of using properly phased data as input (see Mitchell et al. 2012)\n",
    "#Implements singular value truncation at cutoff defined by noise (see Mitchell et al. 2012)\n",
    "\n",
    "#Here are several booleans which can be used to follow the algorithm\n",
    "plot_s_decay = False\n",
    "plot_projected = True\n",
    "plot_projected_3d = False\n",
    "plot_compressed = True\n",
    "plot_compressed_ordered = True\n",
    "numpy_image = False\n",
    "visualize_guess = False\n",
    "S_curve = False # Must be True to use any of the booleans below\n",
    "gen_S_curve_data = False # Time intensive\n",
    "plot_S_curve = False\n",
    "S_curve_guess = False\n",
    "\n",
    "print \"Constructing kernels...\"\n",
    "Nx = 40\n",
    "Ny = 40\n",
    "log_Nx_ax = linspace(log10(3e-3),log10(30),Nx) # T1\n",
    "log_Ny_ax = linspace(log10(3e-3),log10(30),Ny) # T2\n",
    "tau1 = data_nd.getaxis('tau1')\n",
    "tau2 = data_nd.getaxis('tau2')\n",
    "N1_4d = reshape(tau1,(shape(tau1)[0],1,1,1))\n",
    "N2_4d = reshape(tau2,(1,shape(tau2)[0],1,1))\n",
    "Nx_4d = reshape(10**log_Nx_ax,(1,1,shape(log_Nx_ax)[0],1))\n",
    "Ny_4d = reshape(10**log_Ny_ax,(1,1,1,shape(log_Ny_ax)[0]))\n",
    "print \"Shape of parameter of interest (x) axis\",shape(log_Nx_ax),shape(Nx_4d)\n",
    "print \"Shape of parameter of interest (y) axis\",shape(log_Ny_ax),shape(Ny_4d)\n",
    "print \"Shape of indirect dimension (tau1) axis\",shape(tau1),shape(N1_4d)\n",
    "print \"Shape of indirect dimension (tau2) axis\",shape(tau2),shape(N2_4d)\n",
    "k1 = (1.-2*exp(-N1_4d/Nx_4d))\n",
    "k2 = exp(-N2_4d/Ny_4d)\n",
    "print \"Shape of K1 (relates tau1 and x)\",shape(k1)\n",
    "print \"Shape of K2 (relates tau2 and y)\",shape(k2)\n",
    "k1_sqz = squeeze(k1)\n",
    "k2_sqz = squeeze(k2)\n",
    "U1,S1_row,V1 = np.linalg.svd(k1_sqz,full_matrices=False)\n",
    "print \"SVD of K1\",map(lambda x: x.shape, (U1, S1_row, V1))\n",
    "U2,S2_row,V2 = np.linalg.svd(k2_sqz,full_matrices=False)\n",
    "print \"SVD of K2\",map(lambda x: x.shape, (U2, S2_row, V2))\n",
    "\n",
    "print \"\"\n",
    "print \"*** BEGINNING COMPRESSION ***\"\n",
    "print \"\"\n",
    "data_max = amax(data_nd.data)\n",
    "print \"Maximum in the data\",data_max\n",
    "s_cutoff = noise_floor/data_max\n",
    "print \"Cutoff singular values below\",s_cutoff \n",
    "for S1_i in xrange(shape(S1_row)[0]):\n",
    "    if S1_row[S1_i] < s_cutoff:\n",
    "        print \"Truncate S1 at index\",S1_i\n",
    "        choose_s1 = S1_i\n",
    "        break\n",
    "for S2_i in xrange(shape(S2_row)[0]):\n",
    "    if S2_row[S2_i] < s_cutoff:\n",
    "        print \"Truncate S2 at index\",S2_i\n",
    "        choose_s2 = S2_i\n",
    "        break\n",
    "        \n",
    "if plot_s_decay:\n",
    "    with figlist_var() as fl:\n",
    "        fl.next('singular values',figsize=(12,8))\n",
    "        semilogy(S1_row,'o-',label='S1',alpha=0.2)\n",
    "        semilogy(S2_row,'o-',label='S2',alpha=0.2)\n",
    "        for j,val in enumerate(S1_row):\n",
    "            annotate('%0.3f'%(val),(j,val),\n",
    "                    ha='left',va='bottom',rotation=10)\n",
    "        for j,val in enumerate(S2_row):\n",
    "            annotate('%0.3f'%(val),(j,val),\n",
    "                    ha='left',va='bottom',rotation=10)\n",
    "        xlabel('Index')\n",
    "        ylabel('Singular values')\n",
    "        grid(b=True)\n",
    "        legend()\n",
    "\n",
    "print \"Uncompressed singular row vector for K1\",S1_row.shape\n",
    "S1_row = S1_row[0:choose_s1]\n",
    "print \"Compressed singular value row vector for K1\",S1_row.shape\n",
    "V1 = V1[0:choose_s1,:]\n",
    "U1 = U1[:,0:choose_s1]\n",
    "print \"Compressed V matrix for K1\",V1.shape\n",
    "print \"Comrpessed U matrix for K1\",U1.shape\n",
    "\n",
    "print \"Uncompressed singular row vector for K2\",S2_row.shape\n",
    "S2_row = S2_row[0:choose_s2]\n",
    "print \"Compressed singular value row vector for K2\",S2_row.shape\n",
    "V2 = V2[0:choose_s2,:]\n",
    "U2 = U2[:,0:choose_s2]\n",
    "print \"Compressed V matrix for K2\",V2.shape\n",
    "print \"Compressed U matrix for K2\",U2.shape\n",
    "\n",
    "I_S1 = eye(S1_row.shape[0])\n",
    "S1 = S1_row*I_S1\n",
    "print \"Non-zero singular value matrix for K1\",S1.shape\n",
    "\n",
    "I_S2 = eye(S2_row.shape[0])\n",
    "S2 = S2_row*I_S2\n",
    "print \"Non-zero singular value matrix for K2\",S2.shape\n",
    "\n",
    "\n",
    "data_proj = U1.dot(U1.T.dot(data.dot(U2.dot(U2.T))))\n",
    "\n",
    "if plot_projected:\n",
    "    for tau1_index in xrange(shape(data_proj)[0]):\n",
    "        title('projected data')\n",
    "        plot(data_proj[tau1_index,:])\n",
    "    show()\n",
    "if plot_projected_3d:\n",
    "    nd_proj = nddata(data_proj,['N1','N2'])\n",
    "    nd_proj.name('Projected data')\n",
    "    nd_proj.setaxis('N1',data_nd.getaxis('tau1')).rename('N1',r'$\\tau_{1}$')\n",
    "    nd_proj.setaxis('N2',data_nd.getaxis('tau2')).rename('N2',r'$\\tau_{2}$')\n",
    "    nd_proj.meshplot(cmap=cm.viridis)\n",
    "\n",
    "print \"Projected data dimensions:\",shape(data_proj)\n",
    "data_compr = U1.T.dot(data.dot(U2))\n",
    "print \"Compressed data dimensioins:\",shape(data_compr)\n",
    "\n",
    "comp = data_compr\n",
    "comp = reshape(comp,(shape(data_compr))[0]*(shape(data_compr))[1])\n",
    "\n",
    "if plot_compressed:\n",
    "    figure()\n",
    "    for x in xrange((shape(data_compr))[1]):\n",
    "        plot(data_compr[:,x],'-.')\n",
    "    ylabel('Compressed data')\n",
    "    xlabel('Index')\n",
    "    show()\n",
    "\n",
    "if plot_compressed_ordered:\n",
    "    figure()\n",
    "    plot(comp,'-.')\n",
    "    ylabel('Compressed data')\n",
    "    xlabel('Index')\n",
    "    show()\n",
    "\n",
    "K1 = S1.dot(V1)\n",
    "K2 = S2.dot(V2)\n",
    "print \"Compressed K1\",shape(K1)\n",
    "print \"Compressed K2\",shape(K2)\n",
    "\n",
    "K1 = reshape(K1, (shape(K1)[0],1,shape(K1)[1],1))\n",
    "K2 = reshape(K2, (1,shape(K2)[0],1,shape(K2)[1]))\n",
    "K0 = K1*K2\n",
    "K0 = reshape(K0, (shape(K1)[0]*shape(K2)[1],shape(K1)[2]*shape(K2)[3]))\n",
    "print \"Compressed tensor kernel\",shape(K0)\n",
    "print \"* Should be (\",shape(S1)[0],\"*\",shape(S2)[0],\") x (\",shape(Nx_4d)[2],\"*\",shape(Ny_4d)[3],\")\"\n",
    "#END COMPRESSION\n",
    "\n",
    "\n",
    "print \"\"\n",
    "print \"*** FINISHED COMPRESSION ***\"\n",
    "print \"\"\n",
    "\n",
    "datac_lex = []\n",
    "for m in xrange(shape(data_compr)[0]):\n",
    "    for l in xrange(shape(data_compr)[1]):\n",
    "        temp = data_compr[m][l]\n",
    "        datac_lex.append(temp)\n",
    "print \"Dimension of lexicographically ordered data:\",shape(datac_lex)[0]\n",
    "print \"Should match first dimension of compressed tensor kernel K0 which is\",shape(K0)[0]\n",
    "\n",
    "nnls_noreg = False\n",
    "if nnls_noreg:\n",
    "    x, rnorm = nnls(K0,datac_lex)\n",
    "    solution = reshape(x,(Nx,Ny))\n",
    "    figure()\n",
    "    title('Estimate, no regularization')\n",
    "    image(solution)\n",
    "    show()\n",
    "    \n",
    "print \"\"\n",
    "print \"*** BEGINNING REGULARIZATION ***\"\n",
    "print \"\"\n",
    "\n",
    "datac_lex = array(datac_lex)\n",
    "datac_lex = datac_lex[:,newaxis]\n",
    "print \"Lexicographically orderd data:\",shape(datac_lex)\n",
    "\n",
    "dimension = K0.shape[1]\n",
    "def A_prime(val,dimension):\n",
    "    A_prime = r_[K0, val*eye(dimension)]\n",
    "    return A_prime\n",
    "\n",
    "b_prime = r_[datac_lex,zeros((dimension,1))]\n",
    "b_prime = b_prime.squeeze()\n",
    "print \"Shape of b vector\",shape(b_prime)\n",
    "m_vec = datac_lex\n",
    "\n",
    "\n",
    "\n",
    "if S_curve:\n",
    "    if gen_S_curve_data:\n",
    "        lambda_range = logspace(log10(8e-4),log10(2e4),3)\n",
    "        rnorm_list = empty_like(lambda_range)\n",
    "        smoothing_list = empty_like(lambda_range)\n",
    "        alt_norm_list = empty_like(lambda_range)\n",
    "        for index,lambda_val in enumerate(lambda_range):\n",
    "            print \"index\",index\n",
    "            soln,temp_rn = nnls(A_prime(lambda_val,dimension),b_prime)\n",
    "            rnorm_list[index] = temp_rn\n",
    "            f_vec = soln[:,newaxis]\n",
    "            alpha = lambda_val**2\n",
    "            c_vec = dot(K0,f_vec) - m_vec\n",
    "            c_vec /= -alpha\n",
    "            alt_temp = linalg.norm(c_vec)*alpha\n",
    "            alt_norm_list[index] = alt_temp\n",
    "            smoothing_list[index] = lambda_val\n",
    "    if plot_S_curve:  \n",
    "        figure('using NNLS output norm')\n",
    "        rnorm_axis = array(rnorm_list)\n",
    "        smoothing_axis = array(smoothing_list)\n",
    "        plot(log10(smoothing_axis**2),rnorm_axis)\n",
    "        show()\n",
    "        figure();title('using LV norm')\n",
    "        altnorm_axis = array(alt_norm_list)\n",
    "        smoothing_axis = array(smoothing_list)\n",
    "        plot(log10(smoothing_axis**2),altnorm_axis,'-.',c='k')\n",
    "        xlabel(r'log($\\alpha$)')\n",
    "        ylabel(r'$\\chi$($\\alpha$)')\n",
    "        gridandtick(gca())\n",
    "        show() \n",
    "    if S_curve_guess:\n",
    "        heel = raw_input(\"heel of S curve: \")\n",
    "        heel_alpha = 10**heel\n",
    "        heel_lambda = sqrt(heel_alpha)\n",
    "        print \"Alpha\",heel_alpha\n",
    "        print \"Lambda\",heel_lambda\n",
    "        guess_lambda = heel_lambda\n",
    "\n",
    "if not S_curve:\n",
    "    guess_lambda = 600 # Set to any desired variable\n",
    "    alpha = guess_lambda**2\n",
    "    print \"Alpha\",alpha\n",
    "    print \"Lambda\",guess_lambda\n",
    "\n",
    "if visualize_guess:\n",
    "    print \"Estimating solution for guessed smoothing parameter...\"\n",
    "    opt_vec = nnls_reg(guess_lambda)\n",
    "    solution = reshape(opt_vec,(Nx,Ny))\n",
    "    figure()\n",
    "    title(r'Est F(log$(T_{1}$),log$(T_{2})$, $\\lambda$ = %0.3f'%(guess_lambda))\n",
    "    image(solution);show()\n",
    "print \"\"\n",
    "print \"*** BEGINNING MODIFIED BRD OPTIMIZATION ***\"\n",
    "print \"\"\n",
    "opt_val = mod_BRD(guess=guess_lambda,maxiter=20)\n",
    "print \"OPTIMIZED LAMBDA:\",opt_val\n",
    "print \"\"\n",
    "print \"*** FINDING OPTIMIZED SOLUTION ***\"\n",
    "print \"\"\n",
    "opt_vec = nnls_reg(opt_val)\n",
    "solution = reshape(opt_vec,(Nx,Ny))\n",
    "if numpy_image:\n",
    "    figure()\n",
    "    title(r'Est F(log$(T_{1}$),log$(T_{2})$, $\\lambda$ = %0.2f'%(opt_val))\n",
    "    image(solution);show()\n",
    "nd_solution = nddata(solution,['log(T1)','log(T2)'])\n",
    "nd_solution.setaxis('log(T1)',log_Nx_ax.copy())\n",
    "nd_solution.setaxis('log(T2)',log_Ny_ax.copy())\n",
    "figure();title(r'Peak #1: Estimated F(log$(T_{1})$,log($T_{2}$)), $\\lambda$ = %0.2f'%opt_val)\n",
    "nd_solution.contour(labels=False)\n",
    "gcf().subplots_adjust(bottom=0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Anaconda2]",
   "language": "python",
   "name": "Python [Anaconda2]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
